{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import io\n",
    "import requests\n",
    "import datetime\n",
    "import ondemand\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from scipy.stats import pearsonr\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from pandas.io.common import EmptyDataError\n",
    "from requests.exceptions import HTTPError\n",
    "from plotly.graph_objs import *\n",
    "import plotly.io as pio\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from apiclient.discovery import build\n",
    "#from oauth2client.service_account import ServiceAccountCredentials\n",
    "import httplib2\n",
    "from oauth2client import client\n",
    "from oauth2client import file\n",
    "from oauth2client import tools\n",
    "####Google Analytics Module\n",
    "class GA(object): \n",
    "    def __init__(self, start_date, end_date):\n",
    "        self.page_view = None\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "    def initialize_analyticsreporting(self):\n",
    "        \"\"\"\n",
    "          Initializes the analyticsreporting service object.\n",
    "\n",
    "      Returns:\n",
    "        analytics an authorized analyticsreporting service object.\n",
    "        \"\"\"\n",
    "        SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\n",
    "        DISCOVERY_URI = ('https://analyticsreporting.googleapis.com/$discovery/rest')\n",
    "        CLIENT_SECRETS_PATH = 'client_secrets.json' # Path to client_secrets.json file.\n",
    "      # Parse command-line arguments.\n",
    "        parser = argparse.ArgumentParser(\n",
    "          formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "          parents=[tools.argparser])\n",
    "        flags = parser.parse_args([])\n",
    "\n",
    "      # Set up a Flow object to be used if we need to authenticate.\n",
    "        flow = client.flow_from_clientsecrets(\n",
    "          CLIENT_SECRETS_PATH, scope=SCOPES,\n",
    "          message=tools.message_if_missing(CLIENT_SECRETS_PATH))\n",
    "\n",
    "      # Prepare credentials, and authorize HTTP object with them.\n",
    "      # If the credentials don't exist or are invalid run through the native client\n",
    "      # flow. The Storage object will ensure that if successful the good\n",
    "      # credentials will get written back to a file.\n",
    "        storage = file.Storage('analyticsreporting.dat')\n",
    "        credentials = storage.get()\n",
    "        if credentials is None or credentials.invalid:\n",
    "            credentials = tools.run_flow(flow, storage, flags)\n",
    "        http = credentials.authorize(http=httplib2.Http())\n",
    "\n",
    "      # Build the service object.\n",
    "        analytics = build('analytics', 'v4', http=http, discoveryServiceUrl=DISCOVERY_URI)\n",
    "        return analytics\n",
    "\n",
    "    def get_report(self, analytics, symbol):\n",
    "        VIEW_ID = '108608708'#barchart.com view_id\n",
    "        #set filter pagePath according to different symbol.\n",
    "        final_filter = 'ga:pagePath=~(?i)/stocks/quotes/{}'.format(symbol)\n",
    "      # Use the Analytics Service Object to query the Analytics Reporting API V4.\n",
    "        return analytics.reports().batchGet(\n",
    "          body={\n",
    "            'reportRequests': [\n",
    "               {\n",
    "              'viewId': VIEW_ID,\n",
    "              'dateRanges': [{'startDate': self.start_date, 'endDate': self.end_date}],\n",
    "              'metrics': [{'expression': 'ga:pageviews'}],\n",
    "              'filtersExpression' : final_filter,\n",
    "              'dimensions':\n",
    "                     [\n",
    "                        {\n",
    "                         'name': 'ga:date'   \n",
    "                        }                         \n",
    "                     ]\n",
    "                }\n",
    "               ]\n",
    "          }\n",
    "      ).execute()\n",
    "    def main(self, symbol):\n",
    "        analytics = self.initialize_analyticsreporting()\n",
    "        response = self.get_report(analytics, symbol)\n",
    "        report = response.get('reports', [])\n",
    "        final_result = {}\n",
    "        try:\n",
    "            #get our date and pageview results\n",
    "            for item in report[0].get('data', {}).get('rows', []):\n",
    "                date = item['dimensions'][0][:4] +'-'+ item['dimensions'][0][4:6]+\\\n",
    "                                          '-'+item['dimensions'][0][6:]\n",
    "                final_result[date] = item['metrics'][0]['values']\n",
    "            df = pd.DataFrame.from_dict(final_result, orient='index')\n",
    "            df = df.reset_index()\n",
    "            df = df.rename(index=str, columns={'index': 'date', 0: \"page_views\"})\n",
    "            self.page_view = df\n",
    "        except:\n",
    "            print(symbol + ' does not have pageview!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool as ThreadPool\n",
    "from multiprocessing import Manager\n",
    "class PAGE_VIEW(object):\n",
    "    def __init__(self, start_date, end_date):\n",
    "        #we need to catch error, if dates are illeagle\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.page_views = Manager().dict()\n",
    "    def get_history(self, symbols):\n",
    "        mydata = {}\n",
    "        for i, t in enumerate(symbols):\n",
    "            url_history = 'https://ondemand.websol.barchart.com/getHistory.csv?apikey=OnDemand&symbol={}&type=daily&startDate={}&endDate={}&maxRecords=1000&interval=60&order=asc&sessionFilter=EFK&splits=true&dividends=true&volume=sum&nearby=1&jerq=true&exchange=NYSE%2CAMEX%2CNASDAQ&backAdjust=false&daysToExpiration=1&contractRoll=expiration'.\\\n",
    "                format(t, self.start_date, self.end_date)\n",
    "            try:\n",
    "                data_history = pd.read_csv(url_history)\n",
    "                data_history = data_history.rename(columns={'tradingDay': 'date'})\n",
    "                data_history = data_history.rename(columns={'close': 'close_price($)'})\n",
    "                mydata[t] = data_history\n",
    "                if data_history.empty:\n",
    "                    print(t + ' has no history data during this period')\n",
    "            except:\n",
    "                print(t + ' has no history data during this period')\n",
    "        return mydata\n",
    "    ### mutiprocessing\n",
    "    def parallel(self, item):\n",
    "            ga = GA(self.start_date, self.end_date)\n",
    "            ga.main(item)\n",
    "            if ga.page_view is None:\n",
    "                return\n",
    "            self.page_views[item] = ga.page_view\n",
    "    def get_page_view(self, all_symbols):\n",
    "        pool = ThreadPool(10)\n",
    "        pool.map(self.parallel, all_symbols)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    ###combine history and pageview into one dataframe\n",
    "    def main(self, symbols, re_run = False):\n",
    "        history = self.get_history(symbols)\n",
    "        symbol_group = symbols[:]\n",
    "        while symbol_group:\n",
    "            if len(symbol_group) > 80:\n",
    "                temp = symbol_group[:80]\n",
    "                symbol_group = symbol_group[80:]\n",
    "                self.get_page_view(temp)\n",
    "                time.sleep(100)\n",
    "            else:\n",
    "                self.get_page_view(symbol_group)\n",
    "                symbol_group = None\n",
    "        page_view = self.page_views\n",
    "        final_result={}\n",
    "        if page_view:\n",
    "            to_remove = []\n",
    "            for item in symbols:\n",
    "                try:\n",
    "                    history[item]['date'] = history[item]['date'].apply(str)\n",
    "                    page_view[item]['date'] = page_view[item]['date'].apply(str)\n",
    "                    history[item]['date'] = history[item]['date'].str[:10]\n",
    "                    temp = pd.merge(history[item], page_view[item])\n",
    "                    final_result[item] = temp\n",
    "                except KeyError as ke:\n",
    "                    to_remove.append(item)\n",
    "                    print('Skip ' + item+' !!!')\n",
    "            for item in to_remove:\n",
    "                symbols.remove(item)\n",
    "        return final_result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entry module, and we use this module plot graph, save local files\n",
    "class Barchart(object):\n",
    "    def __init__(self):\n",
    "        self.myrawdata = None\n",
    "        self.start_date = None\n",
    "        self.end_date = None\n",
    "    def get_earning_date(self, symbol):\n",
    "        url_earning = 'https://ondemand.websol.barchart.com/getCorporateActions.csv?apikey=ondemand&symbols={}&startDate={}&endDate={}&eventType=earnings&maxRecords=5'.\\\n",
    "                       format(symbol, self.start_date, self.end_date)\n",
    "        try:\n",
    "            earning_date = pd.read_csv(url_earning)\n",
    "            return earning_date\n",
    "        except EmptyDataError as ede:\n",
    "            print(symbol + ' does not have earning_date during this period!!!')\n",
    "            return pd.DataFrame([])\n",
    "    # get outstanding shares for maket value calculation       \n",
    "    def get_shares(self, symbol):\n",
    "\n",
    "        url = 'https://ondemand.websol.barchart.com/getFinancialHighlights.csv?apikey=OnDemand&symbols={}&fields=lastQtrEPS%2CannualEPS%2CttmEPS'.\\\n",
    "                format(symbol)\n",
    "        try:\n",
    "            fundmantal = pd.read_csv(url)\n",
    "            if fundmantal.empty:\n",
    "                print(symbol + ' does not have public market value!!!')\n",
    "            else:\n",
    "                return fundmantal.loc[0, 'sharesOutstanding']\n",
    "        except HTTPError as he:\n",
    "            print('getFinancialHighlights API Error!!! Run again')\n",
    "    # In order to plot highest correlation coefficient and lowest correlation coefficient symbol, we need to\n",
    "    #separate_data and sort them.\n",
    "    def separate_data(self, my_csv, key):\n",
    "        plot_negative = my_csv.copy()\n",
    "        plot_positive = my_csv.copy()\n",
    "        plot_positive = plot_positive[~(plot_positive[key] < 0)]\n",
    "        plot_negative = plot_negative[(plot_negative[key] < 0)]\n",
    "        plot_negative = plot_negative.sort_values(by = key)\n",
    "        plot_positive = plot_positive.sort_values(by = key, ascending = False)\n",
    "        plot_negative = plot_negative.reset_index(drop=True)\n",
    "        plot_positive = plot_positive.reset_index(drop = True)\n",
    "        return (plot_positive, plot_negative)\n",
    "    def plot_graph(self, plot_positive, plot_negative, x, y1, y2, corr = None, key = None, pageviewfiltered = False):\n",
    "        root = ''\n",
    "        if pageviewfiltered:\n",
    "            root = 'pageViewFiltered/'\n",
    "        if not plot_positive.empty:\n",
    "            plot2 = plot_positive.loc[0, 'symbol']\n",
    "            earning_date = self.get_earning_date(plot2)\n",
    "            data_list = []\n",
    "            shapes = []\n",
    "            annotations = []\n",
    "            if  not earning_date.empty:\n",
    "                data_list = list(earning_date['eventDate'])\n",
    "            else:\n",
    "                shapes = None\n",
    "                annotations = None   \n",
    "            for item in data_list:\n",
    "                temp_shape = {\n",
    "                        'type': 'line',\n",
    "                        'xref': 'x',\n",
    "                        'yref': 'paper',\n",
    "                        'x0': item,\n",
    "                        'y0': 0,\n",
    "                        'x1': item,\n",
    "                        'y1': 1,\n",
    "                        'line': {\n",
    "                            'color': 'rgb(193, 191, 191)',\n",
    "                            'width': 1.5,\n",
    "                                }\n",
    "                    \n",
    "                    }\n",
    "                temp_annotations = {\n",
    "                         'x' : item,\n",
    "                         'y' : 1,\n",
    "                        'xref' : 'x',\n",
    "                        'yref' : 'paper',\n",
    "                        'text' : 'Earning Date: ' + item,\n",
    "                        'showarrow' : True,\n",
    "                        'arrowhead' : 7,\n",
    "                        'ax' : 0,\n",
    "                        'ay' : -40\n",
    "                    \n",
    "                                    }\n",
    "                shapes.append(temp_shape)\n",
    "                annotations.append(temp_annotations)\n",
    "            #print(shapes) #test1\n",
    "            mydf = self.myrawdata[plot2].copy()\n",
    "            mydf['date_time']= pd.to_datetime(mydf['date'])\n",
    "            #myrawdata[plot2] = myrawdata[plot2].set_index(myrawdata[plot2]['date_time'])\n",
    "            trace1 = go.Scatter(\n",
    "                x = mydf[x],\n",
    "                y = mydf[y1],\n",
    "                name= y1\n",
    "            )\n",
    "            trace2 = go.Scatter(\n",
    "                x = mydf[x],\n",
    "                y = mydf[y2],\n",
    "                name= y2,\n",
    "                yaxis='y2'\n",
    "            )\n",
    "            data = [trace1, trace2]\n",
    "            layout = go.Layout(\n",
    "                autosize=True,\n",
    "                title='Correlation Compare for ' + plot2 + ' R = '+\\\n",
    "                           str(plot_positive.loc[0, corr])[:7],\n",
    "                xaxis = dict(title = 'Date',\n",
    "                             autorange=True,\n",
    "                            showline=True,\n",
    "                            showticklabels=True),\n",
    "                yaxis=dict(\n",
    "                        title= y1\n",
    "                        ),\n",
    "                yaxis2=dict(\n",
    "                        title= y2,\n",
    "                        titlefont=dict(\n",
    "                            color='rgb(148, 103, 189)'\n",
    "                            ),\n",
    "                        tickfont=dict(\n",
    "                        color='rgb(148, 103, 189)'\n",
    "                            ),\n",
    "                        overlaying='y',\n",
    "                        side='right'\n",
    "                        ),\n",
    "                shapes = shapes,\n",
    "                annotations = annotations\n",
    "            )\n",
    "            fig = go.Figure(data=data, layout=layout)\n",
    "            path = root + self.start_date + ' to ' + self.end_date + ' ' + key +'/Top Positive'+ '/Correlation Compare for ' + plot2 + ' R = '+ str(plot_positive.loc[0, corr])[:7] + '/'\n",
    "            if not os.path.exists(os.path.dirname(path)):\n",
    "                os.makedirs(os.path.dirname(path))\n",
    "            url = plotly.offline.plot(fig, filename= path + plot2 + ' ' + corr +'.html', auto_open=False)\n",
    "           \n",
    "        else:\n",
    "            path = root + self.start_date + ' to ' + self.end_date + ' ' + key + '/Top Positive' + '/'+ 'We did not find positive correlation coefficient!!!' +'/'\n",
    "            if not os.path.exists(os.path.dirname(path)):\n",
    "                os.makedirs(os.path.dirname(path))\n",
    "            print('We did not find positive correlation coefficient!!!')\n",
    "            \n",
    "        if not plot_negative.empty: \n",
    "            plot1 = plot_negative.loc[0, 'symbol']\n",
    "            earning_date = self.get_earning_date(plot1)\n",
    "            data_list = []\n",
    "            shapes = []\n",
    "            annotations = []\n",
    "            if not earning_date.empty:\n",
    "                data_list = list(earning_date['eventDate'])\n",
    "            else:\n",
    "                shapes = None\n",
    "                annotations = None \n",
    "            for item in data_list:\n",
    "                temp_shape = {\n",
    "                        'type': 'line',\n",
    "                        'xref': 'x',\n",
    "                        'yref': 'paper',\n",
    "                        'x0': item,\n",
    "                        'y0': 0,\n",
    "                        'x1': item,\n",
    "                        'y1': 1,\n",
    "                        'line': {\n",
    "                            'color': 'rgb(193, 191, 191)',\n",
    "                            'width': 1.5,\n",
    "                                }\n",
    "                    \n",
    "                            }\n",
    "                temp_annotations = {\n",
    "                         'x' : item,\n",
    "                         'y' : 1,\n",
    "                        'xref' : 'x',\n",
    "                        'yref' : 'paper',\n",
    "                        'text' : 'Earning Date: ' + item,\n",
    "                        'showarrow' : True,\n",
    "                        'arrowhead' : 7,\n",
    "                        'ax' : 0,\n",
    "                        'ay' : -40\n",
    "                    \n",
    "                                    }\n",
    "                shapes.append(temp_shape)\n",
    "                annotations.append(temp_annotations)\n",
    "            mydf = self.myrawdata[plot1].copy()\n",
    "            mydf['date_time']= pd.to_datetime(mydf['date'])\n",
    "            trace1 = go.Scatter(\n",
    "                x = mydf[x],\n",
    "                y = mydf[y1],\n",
    "                name= y1\n",
    "            )\n",
    "            trace2 = go.Scatter(\n",
    "                x = mydf[x],\n",
    "                y = mydf[y2],\n",
    "                name= y2,\n",
    "                yaxis='y2'\n",
    "            )\n",
    "            data = [trace1, trace2]\n",
    "            layout = go.Layout(\n",
    "                title='Correlation Compare for ' + plot1 + ' R = '+\\\n",
    "                           str(plot_negative.loc[0, corr])[:7],\n",
    "                xaxis = dict(title = 'Date',\n",
    "                            autorange=True,\n",
    "                            showline=True,\n",
    "                            showticklabels=True),\n",
    "                yaxis=dict(\n",
    "                        title= y1\n",
    "                        ),\n",
    "                yaxis2=dict(\n",
    "                        title= y2,\n",
    "                        titlefont=dict(\n",
    "                            color='rgb(148, 103, 189)'\n",
    "                            ),\n",
    "                tickfont=dict(\n",
    "                        color='rgb(148, 103, 189)'\n",
    "                            ),\n",
    "                overlaying='y',\n",
    "                side='right'\n",
    "                ),\n",
    "                shapes = shapes,\n",
    "                annotations = annotations\n",
    "            )\n",
    "            fig = go.Figure(data=data, layout=layout)\n",
    "            path = root + self.start_date + ' to ' + self.end_date + ' ' + key +'/Lowest Negative'+'/Correlation Compare for ' + plot1 + ' R = '+ str(plot_negative.loc[0, corr])[:7] +'/'\n",
    "            if not os.path.exists(os.path.dirname(path)):\n",
    "                os.makedirs(os.path.dirname(path))\n",
    "            url = plotly.offline.plot(fig, filename= path + plot1 + ' ' + corr + '.html', auto_open=False)\n",
    "        else:\n",
    "            path = root + self.start_date + ' to ' + self.end_date + ' ' + key +'/Lowest Negative'+'/'+'We did not find negative correlation coefficient!!!'+'/'\n",
    "            if not os.path.exists(os.path.dirname(path)):\n",
    "                os.makedirs(os.path.dirname(path))\n",
    "            print('We did not find negative correlation coefficient!!!')\n",
    "    def plot_graph_re_run(self, symbols, x, y1, y2, my_csv, corr = None, key = None, pageviewfiltered = False):\n",
    "        root = ''\n",
    "        if pageviewfiltered:\n",
    "            root = 'pageViewFiltered/'\n",
    "        count = 0\n",
    "        for item in symbols:\n",
    "            mydf = self.myrawdata[item].copy()\n",
    "            mydf['date_time']= pd.to_datetime(mydf['date'])\n",
    "            trace1 = go.Scatter(\n",
    "                x = mydf[x],\n",
    "                y = mydf[y1],\n",
    "                name= y1\n",
    "            )\n",
    "            trace2 = go.Scatter(\n",
    "                x = mydf[x],\n",
    "                y = mydf[y2],\n",
    "                name= y2,\n",
    "                yaxis='y2'\n",
    "            )\n",
    "            data = [trace1, trace2]\n",
    "            layout = go.Layout(\n",
    "                autosize=True,\n",
    "                title='Correlation Compare for ' + item + ' R = '+\\\n",
    "                           str(my_csv.loc[count, corr])[:7],\n",
    "                xaxis = dict(title = 'Date',\n",
    "                             autorange=True,\n",
    "                            showline=True,\n",
    "                            showticklabels=True),\n",
    "                yaxis=dict(\n",
    "                        title= y1\n",
    "                        ),\n",
    "                yaxis2=dict(\n",
    "                        title= y2,\n",
    "                        titlefont=dict(\n",
    "                            color='rgb(148, 103, 189)'\n",
    "                            ),\n",
    "                        tickfont=dict(\n",
    "                        color='rgb(148, 103, 189)'\n",
    "                            ),\n",
    "                        overlaying='y',\n",
    "                        side='right'\n",
    "                        ),\n",
    "            )\n",
    "            fig = go.Figure(data=data, layout=layout)\n",
    "            path = root + self.start_date + ' to ' + self.end_date + ' ' + key + '/Correlation Compare for ' + item + ' R = '+ str(my_csv.loc[count, corr])[:7] + '/'\n",
    "            if not os.path.exists(os.path.dirname(path)):\n",
    "                os.makedirs(os.path.dirname(path))\n",
    "            url = plotly.offline.plot(fig, filename = path + '/' + item + ' ' + corr +'.html', auto_open=False)\n",
    "            count += 1\n",
    "    def main(self, symbols, start_date, end_date, re_run = False, pageviewfiltered = False):\n",
    "        \"\"\"\n",
    "        \n",
    "        symbols = input('Please input symbols, example: AMZN, AAPL...: ')\n",
    "        temp = symbols.split(',')\n",
    "        symbols = []\n",
    "        for item in temp:\n",
    "            symbols.append(item.strip().upper())\n",
    "        start_date = input('Please input start date, example:2018-06-06: ')\n",
    "        end_date = input('Please input end date, example:2018-06-06: ')\n",
    "        self.start_date = start_date.strip()\n",
    "        self.end_date = end_date.strip()\n",
    "        now = datetime.datetime.utcnow()\n",
    "        if len(start_date) != 10 or len(end_date) != 10:\n",
    "            print('Your date format is wrong, please try again.')\n",
    "            return\n",
    "        check_start = datetime.datetime(int(start_date[:4]), int(start_date[5:7]), int(start_date[8:]))\n",
    "        check_end = datetime.datetime(int(end_date[:4]), int(end_date[5:7]), int(end_date[8:]))\n",
    "        if check_start > check_end or check_end > now:\n",
    "            print('Your date is wrong, please try again.')\n",
    "            return\n",
    "        \"\"\"\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        pv = PAGE_VIEW(self.start_date, self.end_date)\n",
    "        #getting page_view and history data\n",
    "        if not pv:\n",
    "            return\n",
    "        self.myrawdata = pv.main(symbols)\n",
    "        for item in symbols:\n",
    "            self.myrawdata[item]['page_views'] = self.myrawdata[item]['page_views'].apply(int)\n",
    "            df = self.myrawdata[item]\n",
    "            delta_close = df['close_price($)'].diff()\n",
    "            delta_pageview = df['page_views'].diff()\n",
    "            #delta_volume = df['volume'].diff()\n",
    "            # I decide to use mean to fill the first Nan value\n",
    "            delta_close[0] = delta_close.mean()\n",
    "            delta_pageview[0] = delta_pageview.mean()\n",
    "            #delta_volume[0] = delta_volume.mean()\n",
    "            #mean_close = df['close_price($)'].apply(float).mean()\n",
    "            #close_price_account_for_avg = df['close_price($)'].apply(float)/mean_close\n",
    "            #mean_volume = df['volume'].apply(float).mean()\n",
    "            #volume_account_for_avg = df['volume'].apply(float)/mean_volume\n",
    "            #mean_pageviews = df['page_views'].apply(int).mean()\n",
    "            #pageviews_account_for_avg = df['page_views'].apply(int)/mean_pageviews\n",
    "            df['delta_close_price($)'] = abs(delta_close)\n",
    "            df['delta_pageview'] = delta_pageview\n",
    "            #df['delta_volume'] = abs(delta_volume)\n",
    "            #df['close_price_account_for_avg'] = close_price_account_for_avg\n",
    "            #df['volume_account_for_avg'] = volume_account_for_avg\n",
    "            #df['pageviews_account_for_avg'] = pageviews_account_for_avg\n",
    "        if pageviewfiltered:### filter rawdata\n",
    "            to_remove = []\n",
    "            for item in symbols:\n",
    "                mean_pageviews = self.myrawdata[item]['page_views'].apply(int).mean()\n",
    "                if mean_pageviews < 30:\n",
    "                    to_remove.append(item)\n",
    "            for symb in to_remove:\n",
    "                symbols.remove(symb)\n",
    "                self.myrawdata.pop(symb, None)\n",
    "        my_csv = pd.DataFrame([], columns = ['symbol', 'corr_pageview_close', 'corr_pageview_volume', \\\n",
    "                                             'corr_delta_close_pageview', 'corr_delta_pageview_volume', \\\n",
    "                                             'corr_delta_pageview_delta_close', 'mean_pageviews', \\\n",
    "                                             'start_date', 'end_date',\\\n",
    "                                             'frequency', 'price at the end_date', 'mkt_val(billion)'])\n",
    "        if re_run:# remove first 7 days and last 7 days\n",
    "            for symb in symbols:\n",
    "                earning_date = self.get_earning_date(symb)\n",
    "                earning_date = list(earning_date.eventDate)\n",
    "                for item in earning_date:\n",
    "                    date_type = datetime.datetime(int(item[:4]), int(item[5:7]), int(item[8:]))\n",
    "                    mid = date_type\n",
    "                    left = mid\n",
    "                    right = mid\n",
    "                    self.myrawdata[symb] = self.myrawdata[symb][self.myrawdata[symb].date != str(mid)[:10]]\n",
    "                    for i in range(7):\n",
    "                        left -= datetime.timedelta(days=1)\n",
    "                        right += datetime.timedelta(days=1)\n",
    "                        self.myrawdata[symb] = self.myrawdata[symb][self.myrawdata[symb].date != str(left)[:10]]\n",
    "                        self.myrawdata[symb] = self.myrawdata[symb][self.myrawdata[symb].date != str(right)[:10]]\n",
    "                self.myrawdata[symb] = self.myrawdata[symb].reset_index(drop = True)\n",
    "                    \n",
    "        init_notebook_mode(connected=True)\n",
    "        ### building my_csv\n",
    "        for item in symbols:\n",
    "            shares = self.get_shares(item)\n",
    "            if shares is None:\n",
    "                return\n",
    "            shares = float(shares)/1000000\n",
    "            price = self.myrawdata[item].loc[self.myrawdata[item].shape[0]-1, 'close_price($)']\n",
    "            price_float = float(price)\n",
    "            mkt_val = str(shares*price_float)[:6]\n",
    "            if self.myrawdata[item].empty:\n",
    "                continue\n",
    "            mean_pageviews = self.myrawdata[item]['page_views'].apply(int).mean()\n",
    "            corr_page_close = pearsonr(self.myrawdata[item]['page_views'], self.myrawdata[item]['close_price($)'])\n",
    "            corr_page_volume = pearsonr(self.myrawdata[item]['page_views'], self.myrawdata[item]['volume'])\n",
    "            corr_delta_close_pageview = pearsonr(self.myrawdata[item]['delta_close_price($)'], self.myrawdata[item]['page_views'])\n",
    "            ### 'corr_delta_pageview_delta_close', 'corr_delta_pageview_volume'\n",
    "            corr_delta_pageview_delta_close = pearsonr(self.myrawdata[item]['delta_pageview'], self.myrawdata[item]['delta_close_price($)'])\n",
    "            corr_delta_pageview_volume = pearsonr(self.myrawdata[item]['delta_close_price($)'], self.myrawdata[item]['volume'])\n",
    "            #corr_volume_pageviews_account_for_avg = pearsonr(self.myrawdata[item]['delta_volume'],\\\n",
    "                                                                 #self.myrawdata[item]['pageviews_account_for_avg'])\n",
    "            #corr_close_price_account_for_avg_pageviews_account_for_avg = pearsonr(self.myrawdata[item]['close_price_account_for_avg'],\\\n",
    "                                                                 #self.myrawdata[item]['pageviews_account_for_avg'])\n",
    "            #corr_volume_account_for_avg_pageviews_account_for_avg = pearsonr(self.myrawdata[item]['volume_account_for_avg'],\\\n",
    "                                                                 #self.myrawdata[item]['pageviews_account_for_avg'])\n",
    "            my_csv = my_csv.append({'symbol': item, 'corr_pageview_close' : corr_page_close[0], \\\n",
    "                          'corr_pageview_volume' : corr_page_volume[0], 'corr_delta_close_pageview' : corr_delta_close_pageview[0],\\\n",
    "                                    'corr_delta_pageview_delta_close' : corr_delta_pageview_delta_close[0],\\\n",
    "                                    'corr_delta_pageview_volume' : corr_delta_pageview_volume[0],\\\n",
    "                                    'mean_pageviews' : mean_pageviews, 'start_date' : start_date, \\\n",
    "                          'end_date': end_date, 'frequency' : 'daily', 'price at the end_date':\\\n",
    "                                    price, 'mkt_val(billion)':\\\n",
    "                                   mkt_val}, ignore_index=True)\n",
    "        if not re_run:\n",
    "            print('Symbols in four graphs below chosen based on data sorted by corr_pageview_close!!!')\n",
    "            data_sort_by_corr_pageview_close = self.separate_data(my_csv, key = 'corr_pageview_close')\n",
    "            self.plot_graph(data_sort_by_corr_pageview_close[0], data_sort_by_corr_pageview_close[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'close_price($)', corr = 'corr_pageview_close', key = 'sorted by corr_pageview_close', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph(data_sort_by_corr_pageview_close[0], data_sort_by_corr_pageview_close[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'volume', corr = 'corr_pageview_volume', key = 'sorted by corr_pageview_close', pageviewfiltered = pageviewfiltered)\n",
    "            #print(data_sort_by_corr_pageview_close[0])# test 1\n",
    "            if data_sort_by_corr_pageview_close[0].empty:\n",
    "                sorted_by_corr_pageview_close_top_postive = None\n",
    "            else:\n",
    "                sorted_by_corr_pageview_close_top_postive = data_sort_by_corr_pageview_close[0].loc[0, 'symbol']\n",
    "            if data_sort_by_corr_pageview_close[1].empty:\n",
    "                sorted_by_corr_pageview_close_negative = None\n",
    "            else:\n",
    "                sorted_by_corr_pageview_close_negative = data_sort_by_corr_pageview_close[1].loc[0, 'symbol']\n",
    "            print('Symbols in four graphs below chosen based on data sorted by corr_pageview_volume!!!')\n",
    "            data_sort_by_corr_pageview_volume = self.separate_data(my_csv, key = 'corr_pageview_volume')\n",
    "            self.plot_graph(data_sort_by_corr_pageview_volume[0], data_sort_by_corr_pageview_volume[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'close_price($)', corr = 'corr_pageview_close', key = 'sorted by corr_pageview_volume', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph(data_sort_by_corr_pageview_volume[0], data_sort_by_corr_pageview_volume[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'volume', corr = 'corr_pageview_volume', key = 'sorted by corr_pageview_volume', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph(data_sort_by_corr_pageview_volume[0], data_sort_by_corr_pageview_volume[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'delta_close_price($)', corr = 'corr_delta_close_pageview', key = 'sorted by corr_pageview_volume', pageviewfiltered = pageviewfiltered)\n",
    "            if data_sort_by_corr_pageview_volume[0].empty:\n",
    "                sorted_by_corr_pageview_volume_top_postive = None\n",
    "            else:\n",
    "                sorted_by_corr_pageview_volume_top_postive = data_sort_by_corr_pageview_volume[0].loc[0, 'symbol']\n",
    "            if data_sort_by_corr_pageview_volume[1].empty:\n",
    "                sorted_by_corr_pageview_volume_negative = None\n",
    "            else:\n",
    "                sorted_by_corr_pageview_volume_negative = data_sort_by_corr_pageview_volume[1].loc[0, 'symbol']\n",
    "            print('Symbols in four graphs below chosen based on data sorted by corr_delta_close_pageview!!!')\n",
    "            data_sort_by_corr_delta_close_pageview = self.separate_data(my_csv, key = 'corr_delta_close_pageview')\n",
    "            self.plot_graph(data_sort_by_corr_delta_close_pageview[0], data_sort_by_corr_delta_close_pageview[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'delta_close_price($)', corr = 'corr_delta_close_pageview', key = 'sorted by corr_delta_close_pageview', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph(data_sort_by_corr_delta_close_pageview[0], data_sort_by_corr_delta_close_pageview[1], x = 'date_time',\\\n",
    "                            y1 = 'page_views', y2 = 'volume', corr = 'corr_pageview_volume', \\\n",
    "                            key = 'sorted by corr_delta_close_pageview', pageviewfiltered = pageviewfiltered)\n",
    "            if data_sort_by_corr_delta_close_pageview[0].empty:\n",
    "                sorted_by_corr_delta_close_pageview_top_postive = None\n",
    "            else:\n",
    "                sorted_by_corr_delta_close_pageview_top_postive = data_sort_by_corr_delta_close_pageview[0].loc[0, 'symbol']\n",
    "            if data_sort_by_corr_delta_close_pageview[1].empty:\n",
    "                sorted_by_corr_delta_close_pageview_negative = None\n",
    "            else:\n",
    "                sorted_by_corr_delta_close_pageview_negative = data_sort_by_corr_delta_close_pageview[1].loc[0, 'symbol']\n",
    "            print('Symbols in four graphs below chosen based on data sorted by corr_delta_pageview_delta_close!!!')\n",
    "            data_sort_by_corr_delta_pageview_delta_close = self.separate_data(my_csv, key = 'corr_delta_pageview_delta_close')\n",
    "            self.plot_graph(data_sort_by_corr_delta_pageview_delta_close[0], data_sort_by_corr_delta_pageview_delta_close[1], x = 'date_time',\\\n",
    "                            y1 = 'delta_pageview', y2 = 'delta_close_price($)', corr = 'corr_delta_pageview_delta_close', key = 'sorted by corr_delta_pageview_delta_close', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph(data_sort_by_corr_delta_pageview_delta_close[0], data_sort_by_corr_delta_pageview_delta_close[1], x = 'date_time',\\\n",
    "                            y1 = 'delta_pageview', y2 = 'volume', corr = 'corr_delta_pageview_volume', \\\n",
    "                            key = 'sorted by corr_delta_pageview_delta_close', pageviewfiltered = pageviewfiltered)\n",
    "            if data_sort_by_corr_delta_pageview_delta_close[0].empty:\n",
    "                sorted_by_corr_delta_pageview_delta_close_top_postive = None\n",
    "            else:\n",
    "                sorted_by_corr_delta_pageview_delta_close_top_postive = data_sort_by_corr_delta_pageview_delta_close[0].loc[0, 'symbol']\n",
    "            if data_sort_by_corr_delta_pageview_delta_close[1].empty:\n",
    "                sorted_by_corr_delta_pageview_delta_close_negative = None\n",
    "            else:\n",
    "                sorted_by_corr_delta_pageview_delta_close_negative = data_sort_by_corr_delta_pageview_delta_close[1].loc[0, 'symbol']\n",
    "            print('Symbols in four graphs below chosen based on data sorted by corr_delta_pageview_volume!!!')\n",
    "            data_sort_by_corr_delta_pageview_volume = self.separate_data(my_csv, key = 'corr_delta_pageview_volume')\n",
    "            self.plot_graph(data_sort_by_corr_delta_pageview_volume[0], data_sort_by_corr_delta_pageview_volume[1], x = 'date_time',\\\n",
    "                            y1 = 'delta_pageview', y2 = 'delta_close_price($)', corr = 'corr_delta_pageview_delta_close', key = 'sorted by corr_delta_pageview_volume', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph(data_sort_by_corr_delta_pageview_delta_close[0], data_sort_by_corr_delta_pageview_delta_close[1], x = 'date_time',\\\n",
    "                            y1 = 'delta_pageview', y2 = 'volume', corr = 'corr_delta_pageview_volume', \\\n",
    "                            key = 'sorted by corr_delta_pageview_volume', pageviewfiltered = pageviewfiltered)\n",
    "            if data_sort_by_corr_delta_pageview_volume[0].empty:\n",
    "                sorted_by_corr_delta_pageview_volume_top_postive = None\n",
    "            else:\n",
    "                sorted_by_corr_delta_pageview_volume_top_postive = data_sort_by_corr_delta_pageview_volume[0].loc[0, 'symbol']\n",
    "            if data_sort_by_corr_delta_pageview_volume[1].empty:\n",
    "                sorted_by_corr_delta_pageview_volume_negative = None\n",
    "            else:\n",
    "                sorted_by_corr_delta_pageview_volume_negative = data_sort_by_corr_delta_pageview_volume[1].loc[0, 'symbol']\n",
    "            root = ''\n",
    "            if pageviewfiltered:\n",
    "                if not os.path.exists(os.path.dirname('pageViewFiltered/')):\n",
    "                    os.makedirs(os.path.dirname('pageViewFiltered/'))\n",
    "                root = 'pageViewFiltered/new_'\n",
    "            path = root + 'results_total.csv'\n",
    "            my_csv.to_csv(path)\n",
    "            return (my_csv, sorted_by_corr_pageview_close_top_postive, sorted_by_corr_pageview_close_negative,\\\n",
    "                    sorted_by_corr_pageview_volume_top_postive, sorted_by_corr_pageview_volume_negative,\\\n",
    "                   sorted_by_corr_delta_close_pageview_top_postive, sorted_by_corr_delta_close_pageview_negative,\\\n",
    "                   sorted_by_corr_delta_pageview_delta_close_top_postive, sorted_by_corr_delta_pageview_delta_close_negative,\\\n",
    "                   sorted_by_corr_delta_pageview_volume_top_postive, sorted_by_corr_delta_pageview_volume_negative)\n",
    "        else:\n",
    "            self.plot_graph_re_run(symbols, my_csv = my_csv, x = 'date_time', y1 = 'page_views', y2 = 'close_price($)', corr = 'corr_pageview_close', key = 're_run', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph_re_run(symbols, my_csv = my_csv, x = 'date_time', y1 = 'page_views', y2 = 'volume', corr = 'corr_pageview_volume', key = 're_run', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph_re_run(symbols, my_csv = my_csv, x = 'date_time', y1 = 'page_views', y2 = 'delta_close_price($)', corr = 'corr_delta_close_pageview', key = 're_run', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph_re_run(symbols, my_csv = my_csv, x = 'date_time', y1 = 'delta_pageview', y2 = 'delta_close_price($)', corr = 'corr_delta_pageview_delta_close', key = 're_run', pageviewfiltered = pageviewfiltered)\n",
    "            self.plot_graph_re_run(symbols, my_csv = my_csv, x = 'date_time', y1 = 'delta_pageview', y2 = 'volume', corr = 'corr_delta_pageview_volume', key = 're_run', pageviewfiltered = pageviewfiltered)\n",
    "            root = ''\n",
    "            if pageviewfiltered:\n",
    "                if not os.path.exists(os.path.dirname('pageViewFiltered/')):\n",
    "                    os.makedirs(os.path.dirname('pageViewFiltered/'))\n",
    "                root = 'pageViewFiltered/new_'\n",
    "            path = root + 'results_re_run.csv'\n",
    "            my_csv.to_csv(path)  \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = pd.read_csv('https://ondemand.websol.barchart.com/getETFConstituents.csv?apikey=ondemand&symbol=SPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = []\n",
    "temp = list(sp500.symbol)\n",
    "for item in temp:\n",
    "    if isinstance(item, str):\n",
    "        symbols.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols in four graphs below chosen based on data sorted by corr_pageview_close!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_pageview_volume!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_delta_close_pageview!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_delta_pageview_delta_close!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_delta_pageview_volume!!!\n",
      "We did not find negative correlation coefficient!!!\n"
     ]
    }
   ],
   "source": [
    "test = Barchart()\n",
    "start = '2017-08-09'\n",
    "end = '2018-08-10'\n",
    "results_total = test.main(symbols, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    503.000000\n",
       "mean       0.242265\n",
       "std        0.149409\n",
       "min       -0.103476\n",
       "25%        0.130347\n",
       "50%        0.228659\n",
       "75%        0.348418\n",
       "max        0.719004\n",
       "Name: corr_delta_pageview_delta_close, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_total[0]['corr_delta_pageview_delta_close'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    503.000000\n",
       "mean       0.484101\n",
       "std        0.151704\n",
       "min        0.000245\n",
       "25%        0.383173\n",
       "50%        0.494681\n",
       "75%        0.591100\n",
       "max        0.834469\n",
       "Name: corr_delta_pageview_volume, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_total[0]['corr_delta_pageview_volume'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_run_symbol = set()\n",
    "for i in range(1, len(results_total)):\n",
    "    if results_total[i]:\n",
    "        re_run_symbol.add(results_total[i])\n",
    "re_run_symbol = list(re_run_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "re_run_test = Barchart()\n",
    "re_run_res = re_run_test.main(re_run_symbol, start, end, re_run = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbols in four graphs below chosen based on data sorted by corr_pageview_close!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_pageview_volume!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_delta_close_pageview!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_delta_pageview_delta_close!!!\n",
      "Symbols in four graphs below chosen based on data sorted by corr_delta_pageview_volume!!!\n",
      "We did not find negative correlation coefficient!!!\n"
     ]
    }
   ],
   "source": [
    "### page_view filtered\n",
    "new_test = Barchart()\n",
    "start = '2017-08-09'\n",
    "end = '2018-08-10'\n",
    "new_results_total = new_test.main(symbols, start, end, pageviewfiltered = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    179.000000\n",
       "mean       0.305836\n",
       "std        0.132981\n",
       "min       -0.098406\n",
       "25%        0.214360\n",
       "50%        0.307800\n",
       "75%        0.392746\n",
       "max        0.698904\n",
       "Name: corr_delta_pageview_delta_close, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results_total[0]['corr_delta_pageview_delta_close'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    179.000000\n",
       "mean       0.565890\n",
       "std        0.122111\n",
       "min        0.173567\n",
       "25%        0.496752\n",
       "50%        0.582894\n",
       "75%        0.644516\n",
       "max        0.834469\n",
       "Name: corr_delta_pageview_volume, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results_total[0]['corr_delta_pageview_volume'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_re_run_symbol = set()\n",
    "for i in range(1, len(new_results_total)):\n",
    "    if new_results_total[i]:\n",
    "        new_re_run_symbol.add(new_results_total[i])\n",
    "new_re_run_symbol = list(new_re_run_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EFX', 'GIS', 'SYMC', 'FDX', 'ABMD', 'ICE']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_re_run_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_re_run_test = Barchart()\n",
    "new_re_run_res = new_re_run_test.main(new_re_run_symbol, start, end, re_run = True, pageviewfiltered = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
